{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import init\n",
    "from torchinfo import summary as summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_normal_(m.weight.data, gain=1)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.xavier_normal_(m.weight.data, gain=1)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_orthogonal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal'):\n",
    "    #print('initialization method [%s]' % init_type)\n",
    "    if init_type == 'normal':\n",
    "        net.apply(weights_init_normal)\n",
    "    elif init_type == 'xavier':\n",
    "        net.apply(weights_init_xavier)\n",
    "    elif init_type == 'kaiming':\n",
    "        net.apply(weights_init_kaiming)\n",
    "    elif init_type == 'orthogonal':\n",
    "        net.apply(weights_init_orthogonal)\n",
    "    else:\n",
    "        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unetConv2(nn.Module):\n",
    "    def __init__(self, in_size, out_size, is_batchnorm, n=2, ks=3, stride=1, padding=1):\n",
    "        super(unetConv2, self).__init__()\n",
    "        self.n = n\n",
    "        self.ks = ks\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        s = stride\n",
    "        p = padding\n",
    "        if is_batchnorm:\n",
    "            for i in range(1, n + 1):\n",
    "                conv = nn.Sequential(nn.Conv2d(in_size, out_size, ks, s, p),\n",
    "                                     nn.BatchNorm2d(out_size),\n",
    "                                     nn.ReLU(inplace=True), )\n",
    "                setattr(self, 'conv%d' % i, conv)\n",
    "                in_size = out_size\n",
    "\n",
    "        else:\n",
    "            for i in range(1, n + 1):\n",
    "                conv = nn.Sequential(nn.Conv2d(in_size, out_size, ks, s, p),\n",
    "                                     nn.ReLU(inplace=True), )\n",
    "                setattr(self, 'conv%d' % i, conv)\n",
    "                in_size = out_size\n",
    "\n",
    "        # initialise the blocks\n",
    "        for m in self.children():\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        for i in range(1, self.n + 1):\n",
    "            conv = getattr(self, 'conv%d' % i)\n",
    "            x = conv(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class unetConv3(nn.Module):\n",
    "    def __init__(self, in_size, out_size, is_batchnorm, n=2, ks=3, stride=1, padding=1):\n",
    "        super(unetConv3, self).__init__()\n",
    "        self.n = n\n",
    "        self.ks = ks\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        s = stride\n",
    "        p = padding\n",
    "        if is_batchnorm:\n",
    "            for i in range(1, n + 1):\n",
    "                conv = nn.Sequential(nn.Conv3d(in_size, out_size, ks, s, p),\n",
    "                                     nn.BatchNorm3d(out_size),\n",
    "                                     nn.ReLU(inplace=True), )\n",
    "                setattr(self, 'conv%d' % i, conv)\n",
    "                in_size = out_size\n",
    "\n",
    "        else:\n",
    "            for i in range(1, n + 1):\n",
    "                conv = nn.Sequential(nn.Conv3d(in_size, out_size, ks, s, p),\n",
    "                                     nn.ReLU(inplace=True), )\n",
    "                setattr(self, 'conv%d' % i, conv)\n",
    "                in_size = out_size\n",
    "\n",
    "        # initialise the blocks\n",
    "        for m in self.children():\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        for i in range(1, self.n + 1):\n",
    "            conv = getattr(self, 'conv%d' % i)\n",
    "            x = conv(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class BlockPT(nn.Module):\n",
    "    '''\n",
    "    kwargs or not > 'dual'list kaiba~\n",
    "    spatial_dims = 2 or 3\n",
    "    pooling_params = [kernel_size(==stride), is_ceil]; ex) 8, True\n",
    "    conv_params = [filtermap_size, concat_channels, kernel_size, padding, is_inplace]; ex) 64, 64*5, 3, 1, True\n",
    "    '''\n",
    "    def __init__(self, spatial_dims: int, conv_params: list, pooling_params: list):\n",
    "        super(BlockPT, self).__init__()\n",
    "        assert spatial_dims == 2 or spatial_dims == 3, 'invalid dimension input'\n",
    "\n",
    "        filter_size, concat_channels = conv_params[0], conv_params[1]\n",
    "        pooling_size, is_ceil = pooling_params[0], pooling_params[1]\n",
    "        kernel_size, padding, is_inplace = conv_params[2], conv_params[3], conv_params[4]\n",
    "\n",
    "        if spatial_dims == 2:\n",
    "            self.PT = nn.MaxPool2d(pooling_size, pooling_size, ceil_mode=is_ceil)\n",
    "            self.PT_conv = nn.Conv2d(filter_size, concat_channels, kernel_size, padding=padding)\n",
    "            self.PT_norm = nn.BatchNorm2d(concat_channels)\n",
    "            \n",
    "        elif spatial_dims == 3:\n",
    "            self.PT = nn.MaxPool3d(pooling_size, pooling_size, ceil_mode=is_ceil)\n",
    "            self.PT_conv = nn.Conv3d(filter_size, concat_channels, kernel_size, padding=padding)\n",
    "            self.PT_norm = nn.BatchNorm3d(concat_channels)\n",
    "\n",
    "        self.PT_Layer = nn.Sequential(self.PT, self.PT_conv, self.PT_norm,\n",
    "                                      nn.ReLU(inplace=is_inplace))\n",
    "                \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.PT_Layer(x)\n",
    "        \n",
    "\n",
    "class BlockUT(nn.Module):\n",
    "    '''\n",
    "    kwargs or not > 'dual'list kaiba~\n",
    "    spaital_dims = 2 or 3\n",
    "    scale_params = [scaling_factor]\n",
    "    conv_params = [filtermap_size(or Upchannel), concat_channels, kernel_size, padding, is_inplace]\n",
    "    '''\n",
    "    def __init__(self, spatial_dims: int, conv_params: list, scale_params: list):\n",
    "        super(BlockUT, self).__init__()\n",
    "        assert spatial_dims == 2 or spatial_dims == 3, 'invalid dimension input'\n",
    "        mode = 'bilinear' if spatial_dims == 2 else 'trilinear'\n",
    "    \n",
    "        scale_factor = scale_params[0]\n",
    "        filter_size, concat_channels = conv_params[0], conv_params[1]\n",
    "        kernel_size, padding, is_inplace = conv_params[2], conv_params[3], conv_params[4]\n",
    "                \n",
    "        if spatial_dims == 2:\n",
    "            self.UT_conv = nn.Conv2d(filter_size, concat_channels, kernel_size, padding=padding)\n",
    "            self.UT_norm = nn.BatchNorm2d(concat_channels)\n",
    "            \n",
    "        elif spatial_dims == 3:\n",
    "            self.UT_conv = nn.Conv3d(filter_size, concat_channels, kernel_size, padding=padding) \n",
    "            self.UT_norm = nn.BatchNorm3d(concat_channels)\n",
    "        \n",
    "        self.UT_Layer = nn.Sequential(self.UT_conv, self.UT_norm,\n",
    "                                      nn.Upsample(scale_factor=scale_factor, mode=mode),\n",
    "                                      nn.ReLU(inplace=True))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.UT_Layer(x)\n",
    "        \n",
    "    \n",
    "class BlockCAT(nn.Module):\n",
    "    '''\n",
    "    spatial_dims = 2 or 3\n",
    "    conv_params = [filtermap_size, concat_channels, kernel_size, padding, is_inplace]; ex) 64, 64*5, 3, 1, True\n",
    "    '''\n",
    "    def __init__(self, spatial_dims: int, conv_params: list):\n",
    "        super(BlockCAT, self).__init__()    \n",
    "        assert spatial_dims == 2 or spatial_dims == 3, 'invalid dimension input'\n",
    "\n",
    "        filter_size, concat_channels = conv_params[0], conv_params[1]\n",
    "        kernel_size, padding, is_inplace = conv_params[2], conv_params[3], conv_params[4] \n",
    "        \n",
    "        if spatial_dims == 2:\n",
    "            self.CAT_conv = nn.Conv2d(filter_size, concat_channels, kernel_size, padding=padding)\n",
    "            self.CAT_norm = nn.BatchNorm2d(concat_channels)\n",
    "        \n",
    "        elif spatial_dims == 3:\n",
    "            self.CAT_conv = nn.Conv3d(filter_size, concat_channels, kernel_size, padding=padding)\n",
    "            self.CAT_norm = nn.BatchNorm3d(concat_channels)\n",
    "            \n",
    "        self.CAT_Layer = nn.Sequential(self.CAT_conv, self.CAT_norm,\n",
    "                                       nn.ReLU(inplace=is_inplace))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.CAT_Layer(x)\n",
    "            \n",
    "        \n",
    "class BlockFUSION(nn.Module):\n",
    "    '''\n",
    "    spatial_dims = 2 or 3\n",
    "    conv_params = [filtermap_size, concat_channels, kernel_size, padding, is_inplace]\n",
    "    '''\n",
    "    def __init__(self, spatial_dims: int, conv_params: list):\n",
    "        super(BlockFUSION, self).__init__()\n",
    "        assert spatial_dims == 2 or spatial_dims == 3, 'invalid dimension input'\n",
    "        \n",
    "        filter_size, concat_channels = conv_params[0], conv_params[1]\n",
    "        kernel_size, padding, is_inplace = conv_params[2], conv_params[3], conv_params[4]\n",
    "        \n",
    "        if spatial_dims == 2:\n",
    "            self.FUSION_conv = nn.Conv2d(filter_size, concat_channels, kernel_size, padding=padding)\n",
    "            self.FUSION_norm = nn.BatchNorm2d(concat_channels)\n",
    "            \n",
    "        elif spatial_dims == 3:\n",
    "            self.FUSION_conv = nn.Conv3d(filter_size, concat_channels, kernel_size, padding=padding)\n",
    "            self.FUSION_norm = nn.BatchNorm3d(concat_channels)\n",
    "        \n",
    "        self.FUSION_Layer = nn.Sequential(self.FUSION_conv, self.FUSION_norm,\n",
    "                                          nn.ReLU(inplace=is_inplace))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.FUSION_Layer(x) # x must be concatenated by torch.cat method, 5 tensors with axis = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomUNet3Plus(nn.Module):\n",
    "    def __init__(self, in_channels: int=1, n_classes: int=1, spatial_dims: int=3, feature_scale: int=4, is_deconv: bool=True, is_batchnorm: bool=True, is_sigmoid: bool=True):\n",
    "        super(CustomUNet3Plus, self).__init__()\n",
    "        self.filters = [64, 128, 256, 512, 1024] # filter map list\n",
    "        self.is_sigmoid = is_sigmoid    # boolean: apply sigmoid method or not\n",
    "\n",
    "        self.CatBlocks = 5\n",
    "        self.CatChannels = self.filters[0]\n",
    "        self.UpChannels = self.CatChannels * self.CatBlocks\n",
    "\n",
    "        self.is_deconv = is_deconv\n",
    "        self.in_channels = in_channels\n",
    "        self.is_batchnorm = is_batchnorm\n",
    "        self.spatial_dims = spatial_dims\n",
    "        # self.feature_scale = feature_scale\n",
    "\n",
    "        ### Encoder ###\n",
    "        if self.spatial_dims==2: \n",
    "            self.conv1 = unetConv2(self.in_channels, self.filters[0], self.is_batchnorm)\n",
    "            self.conv2 = unetConv2(self.filters[0], self.filters[1], self.is_batchnorm)\n",
    "            self.conv3 = unetConv2(self.filters[1], self.filters[2], self.is_batchnorm)\n",
    "            self.conv4 = unetConv2(self.filters[2], self.filters[3], self.is_batchnorm)\n",
    "            self.conv5 = unetConv2(self.filters[3], self.filters[4], self.is_batchnorm)   # like bottle neck \n",
    "            \n",
    "            self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.output = nn.Conv2d(self.UpChannels, n_classes, 3, padding=1)\n",
    "                \n",
    "        elif self.spatial_dims==3:\n",
    "            self.conv1 = unetConv3(self.in_channels, self.filters[0], self.is_batchnorm)\n",
    "            self.conv2 = unetConv3(self.filters[0], self.filters[1], self.is_batchnorm)\n",
    "            self.conv3 = unetConv3(self.filters[1], self.filters[2], self.is_batchnorm)\n",
    "            self.conv4 = unetConv3(self.filters[2], self.filters[3], self.is_batchnorm)\n",
    "            self.conv5 = unetConv3(self.filters[3], self.filters[4], self.is_batchnorm)   # like bottle neck \n",
    "            \n",
    "            self.maxpool1 = nn.MaxPool3d(kernel_size=2)\n",
    "            self.maxpool2 = nn.MaxPool3d(kernel_size=2)\n",
    "            self.maxpool3 = nn.MaxPool3d(kernel_size=2)\n",
    "            self.maxpool4 = nn.MaxPool3d(kernel_size=2)\n",
    "            self.output = nn.Conv3d(self.UpChannels, n_classes, 3, padding=1)\n",
    "       \n",
    "        ### decoder ###     \n",
    "        self.indice1_1 = BlockPT(spatial_dims=self.spatial_dims, conv_params=[self.filters[0], self.CatChannels, 3, 1, True], pooling_params=[8, True])\n",
    "        self.indice2_1 = BlockPT(spatial_dims=self.spatial_dims, conv_params=[self.filters[1], self.CatChannels, 3, 1, True], pooling_params=[4, True])\n",
    "        self.indice3_1 = BlockPT(spatial_dims=self.spatial_dims, conv_params=[self.filters[2], self.CatChannels, 3, 1, True], pooling_params=[2, True])\n",
    "        self.indice4_1 = BlockCAT(spatial_dims=self.spatial_dims, conv_params=[self.filters[3], self.CatChannels, 3, 1, True])\n",
    "        self.indice5_1 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[2], conv_params=[self.filters[4], self.CatChannels, 3, 1, True])\n",
    "\n",
    "        self.indice1_2 = BlockPT(spatial_dims=self.spatial_dims, conv_params=[self.filters[0], self.CatChannels, 3, 1, True], pooling_params=[4, True]) \n",
    "        self.indice2_2 = BlockPT(spatial_dims=self.spatial_dims, conv_params=[self.filters[1], self.CatChannels, 3, 1, True], pooling_params=[2, True])\n",
    "        self.indice3_2 = BlockCAT(spatial_dims=self.spatial_dims, conv_params=[self.filters[2], self.CatChannels, 3, 1, True])\n",
    "        self.indice4_2 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[2], conv_params=[self.UpChannels, self.CatChannels, 3, 1, True])\n",
    "        self.indice5_2 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[4], conv_params=[self.filters[4], self.CatChannels, 3, 1, True])\n",
    "\n",
    "        self.indice1_3 = BlockPT(spatial_dims=self.spatial_dims, conv_params=[self.filters[0], self.CatChannels, 3, 1, True], pooling_params=[2, True]) \n",
    "        self.indice2_3 = BlockCAT(spatial_dims=self.spatial_dims, conv_params=[self.filters[1], self.CatChannels, 3, 1, True])\n",
    "        self.indice3_3 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[2], conv_params=[self.UpChannels, self.CatChannels, 3, 1, True])\n",
    "        self.indice4_3 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[4], conv_params=[self.UpChannels, self.CatChannels, 3, 1, True])\n",
    "        self.indice5_3 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[8], conv_params=[self.filters[4], self.CatChannels, 3, 1, True])\n",
    "        \n",
    "        self.indice1_4 = BlockCAT(spatial_dims=self.spatial_dims, conv_params=[self.filters[0], self.CatChannels, 3, 1, True])\n",
    "        self.indice2_4 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[2], conv_params=[self.UpChannels, self.CatChannels, 3, 1, True])\n",
    "        self.indice3_4 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[4], conv_params=[self.UpChannels, self.CatChannels, 3, 1, True])\n",
    "        self.indice4_4 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[8], conv_params=[self.UpChannels, self.CatChannels, 3, 1, True])\n",
    "        self.indice5_4 = BlockUT(spatial_dims=self.spatial_dims, scale_params=[16], conv_params=[self.filters[4], self.CatChannels, 3, 1, True])\n",
    "        \n",
    "        self.decoder = BlockFUSION(spatial_dims=self.spatial_dims, conv_params=[self.UpChannels, self.UpChannels, 3, 1, True])\n",
    "\n",
    "        # initialise weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv3d): init_weights(m, init_type='kaiming')\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm3d): init_weights(m, init_type='kaiming')\n",
    "\n",
    "                \n",
    "    def forward(self, x):\n",
    "        ### enc ###\n",
    "        x1 = self.conv1(x)\n",
    "        x1_out = self.maxpool1(x1)\n",
    "        \n",
    "        x2 = self.conv2(x1_out)\n",
    "        x2_out = self.maxpool2(x2)\n",
    "        \n",
    "        x3 = self.conv3(x2_out)\n",
    "        x3_out = self.maxpool3(x3)\n",
    "        \n",
    "        x4 = self.conv4(x3_out)\n",
    "        x4_out = self.maxpool4(x4)\n",
    "        \n",
    "        x5_dec = self.conv5(x4_out)        \n",
    "        \n",
    "        ### dec, {dec_class_name}_(level)_idx ###\n",
    "        x4_1 = self.indice1_1(x1)\n",
    "        x4_2 = self.indice2_1(x2)\n",
    "        x4_3 = self.indice3_1(x3)\n",
    "        x4_4 = self.indice4_1(x4)\n",
    "        x4_5 = self.indice5_1(x5_dec)\n",
    "        x4_dec = self.decoder(torch.cat((x4_1, x4_2, x4_3, x4_4, x4_5), 1))\n",
    "\n",
    "        x3_1 = self.indice1_2(x1)\n",
    "        x3_2 = self.indice2_2(x2)\n",
    "        x3_3 = self.indice3_2(x3)        \n",
    "        x3_4 = self.indice4_2(x4_dec)\n",
    "        x3_5 = self.indice5_2(x5_dec)\n",
    "        x3_dec = self.decoder(torch.cat((x3_1, x3_2, x3_3, x3_4, x3_5), 1))\n",
    "        \n",
    "        x2_1 = self.indice1_3(x1)                \n",
    "        x2_2 = self.indice2_3(x2)                \n",
    "        x2_3 = self.indice3_3(x3_dec)                \n",
    "        x2_4 = self.indice4_3(x4_dec)                \n",
    "        x2_5 = self.indice5_3(x5_dec)                \n",
    "        x2_dec = self.decoder(torch.cat((x2_1, x2_2, x2_3, x2_4, x2_5), 1))\n",
    "        \n",
    "        x1_1 = self.indice1_4(x1)\n",
    "        x1_2 = self.indice2_4(x2_dec)\n",
    "        x1_3 = self.indice3_4(x3_dec)\n",
    "        x1_4 = self.indice4_4(x4_dec)\n",
    "        x1_5 = self.indice5_4(x5_dec)\n",
    "        x1_dec = self.decoder(torch.cat((x1_1, x1_2, x1_3, x1_4, x1_5), 1))\n",
    "        \n",
    "        x_out = self.output(x1_dec)\n",
    "        \n",
    "        if self.is_sigmoid == True: return torch.sigmoid(x_out)\n",
    "        else: return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CustomUNet3Plus                          [2, 1, 32, 32]            --\n",
       "├─unetConv2: 1-1                         [2, 64, 32, 32]           --\n",
       "│    └─Sequential: 2-1                   [2, 64, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-1                  [2, 64, 32, 32]           640\n",
       "│    │    └─BatchNorm2d: 3-2             [2, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-3                    [2, 64, 32, 32]           --\n",
       "│    └─Sequential: 2-2                   [2, 64, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-4                  [2, 64, 32, 32]           36,928\n",
       "│    │    └─BatchNorm2d: 3-5             [2, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-6                    [2, 64, 32, 32]           --\n",
       "├─MaxPool2d: 1-2                         [2, 64, 16, 16]           --\n",
       "├─unetConv2: 1-3                         [2, 128, 16, 16]          --\n",
       "│    └─Sequential: 2-3                   [2, 128, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-7                  [2, 128, 16, 16]          73,856\n",
       "│    │    └─BatchNorm2d: 3-8             [2, 128, 16, 16]          256\n",
       "│    │    └─ReLU: 3-9                    [2, 128, 16, 16]          --\n",
       "│    └─Sequential: 2-4                   [2, 128, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-10                 [2, 128, 16, 16]          147,584\n",
       "│    │    └─BatchNorm2d: 3-11            [2, 128, 16, 16]          256\n",
       "│    │    └─ReLU: 3-12                   [2, 128, 16, 16]          --\n",
       "├─MaxPool2d: 1-4                         [2, 128, 8, 8]            --\n",
       "├─unetConv2: 1-5                         [2, 256, 8, 8]            --\n",
       "│    └─Sequential: 2-5                   [2, 256, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-13                 [2, 256, 8, 8]            295,168\n",
       "│    │    └─BatchNorm2d: 3-14            [2, 256, 8, 8]            512\n",
       "│    │    └─ReLU: 3-15                   [2, 256, 8, 8]            --\n",
       "│    └─Sequential: 2-6                   [2, 256, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-16                 [2, 256, 8, 8]            590,080\n",
       "│    │    └─BatchNorm2d: 3-17            [2, 256, 8, 8]            512\n",
       "│    │    └─ReLU: 3-18                   [2, 256, 8, 8]            --\n",
       "├─MaxPool2d: 1-6                         [2, 256, 4, 4]            --\n",
       "├─unetConv2: 1-7                         [2, 512, 4, 4]            --\n",
       "│    └─Sequential: 2-7                   [2, 512, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-19                 [2, 512, 4, 4]            1,180,160\n",
       "│    │    └─BatchNorm2d: 3-20            [2, 512, 4, 4]            1,024\n",
       "│    │    └─ReLU: 3-21                   [2, 512, 4, 4]            --\n",
       "│    └─Sequential: 2-8                   [2, 512, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-22                 [2, 512, 4, 4]            2,359,808\n",
       "│    │    └─BatchNorm2d: 3-23            [2, 512, 4, 4]            1,024\n",
       "│    │    └─ReLU: 3-24                   [2, 512, 4, 4]            --\n",
       "├─MaxPool2d: 1-8                         [2, 512, 2, 2]            --\n",
       "├─unetConv2: 1-9                         [2, 1024, 2, 2]           --\n",
       "│    └─Sequential: 2-9                   [2, 1024, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-25                 [2, 1024, 2, 2]           4,719,616\n",
       "│    │    └─BatchNorm2d: 3-26            [2, 1024, 2, 2]           2,048\n",
       "│    │    └─ReLU: 3-27                   [2, 1024, 2, 2]           --\n",
       "│    └─Sequential: 2-10                  [2, 1024, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-28                 [2, 1024, 2, 2]           9,438,208\n",
       "│    │    └─BatchNorm2d: 3-29            [2, 1024, 2, 2]           2,048\n",
       "│    │    └─ReLU: 3-30                   [2, 1024, 2, 2]           --\n",
       "├─BlockPT: 1-10                          [2, 64, 4, 4]             --\n",
       "│    └─Sequential: 2-11                  [2, 64, 4, 4]             --\n",
       "│    │    └─MaxPool2d: 3-31              [2, 64, 4, 4]             --\n",
       "│    │    └─Conv2d: 3-32                 [2, 64, 4, 4]             36,928\n",
       "│    │    └─BatchNorm2d: 3-33            [2, 64, 4, 4]             128\n",
       "│    │    └─ReLU: 3-34                   [2, 64, 4, 4]             --\n",
       "├─BlockPT: 1-11                          [2, 64, 4, 4]             --\n",
       "│    └─Sequential: 2-12                  [2, 64, 4, 4]             --\n",
       "│    │    └─MaxPool2d: 3-35              [2, 128, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-36                 [2, 64, 4, 4]             73,792\n",
       "│    │    └─BatchNorm2d: 3-37            [2, 64, 4, 4]             128\n",
       "│    │    └─ReLU: 3-38                   [2, 64, 4, 4]             --\n",
       "├─BlockPT: 1-12                          [2, 64, 4, 4]             --\n",
       "│    └─Sequential: 2-13                  [2, 64, 4, 4]             --\n",
       "│    │    └─MaxPool2d: 3-39              [2, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-40                 [2, 64, 4, 4]             147,520\n",
       "│    │    └─BatchNorm2d: 3-41            [2, 64, 4, 4]             128\n",
       "│    │    └─ReLU: 3-42                   [2, 64, 4, 4]             --\n",
       "├─BlockCAT: 1-13                         [2, 64, 4, 4]             --\n",
       "│    └─Sequential: 2-14                  [2, 64, 4, 4]             --\n",
       "│    │    └─Conv2d: 3-43                 [2, 64, 4, 4]             294,976\n",
       "│    │    └─BatchNorm2d: 3-44            [2, 64, 4, 4]             128\n",
       "│    │    └─ReLU: 3-45                   [2, 64, 4, 4]             --\n",
       "├─BlockUT: 1-14                          [2, 64, 4, 4]             --\n",
       "│    └─Sequential: 2-15                  [2, 64, 4, 4]             --\n",
       "│    │    └─Conv2d: 3-46                 [2, 64, 2, 2]             589,888\n",
       "│    │    └─BatchNorm2d: 3-47            [2, 64, 2, 2]             128\n",
       "│    │    └─Upsample: 3-48               [2, 64, 4, 4]             --\n",
       "│    │    └─ReLU: 3-49                   [2, 64, 4, 4]             --\n",
       "├─BlockFUSION: 1-15                      [2, 320, 4, 4]            --\n",
       "│    └─Sequential: 2-16                  [2, 320, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-50                 [2, 320, 4, 4]            921,920\n",
       "│    │    └─BatchNorm2d: 3-51            [2, 320, 4, 4]            640\n",
       "│    │    └─ReLU: 3-52                   [2, 320, 4, 4]            --\n",
       "├─BlockPT: 1-16                          [2, 64, 8, 8]             --\n",
       "│    └─Sequential: 2-17                  [2, 64, 8, 8]             --\n",
       "│    │    └─MaxPool2d: 3-53              [2, 64, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-54                 [2, 64, 8, 8]             36,928\n",
       "│    │    └─BatchNorm2d: 3-55            [2, 64, 8, 8]             128\n",
       "│    │    └─ReLU: 3-56                   [2, 64, 8, 8]             --\n",
       "├─BlockPT: 1-17                          [2, 64, 8, 8]             --\n",
       "│    └─Sequential: 2-18                  [2, 64, 8, 8]             --\n",
       "│    │    └─MaxPool2d: 3-57              [2, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-58                 [2, 64, 8, 8]             73,792\n",
       "│    │    └─BatchNorm2d: 3-59            [2, 64, 8, 8]             128\n",
       "│    │    └─ReLU: 3-60                   [2, 64, 8, 8]             --\n",
       "├─BlockCAT: 1-18                         [2, 64, 8, 8]             --\n",
       "│    └─Sequential: 2-19                  [2, 64, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-61                 [2, 64, 8, 8]             147,520\n",
       "│    │    └─BatchNorm2d: 3-62            [2, 64, 8, 8]             128\n",
       "│    │    └─ReLU: 3-63                   [2, 64, 8, 8]             --\n",
       "├─BlockUT: 1-19                          [2, 64, 8, 8]             --\n",
       "│    └─Sequential: 2-20                  [2, 64, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-64                 [2, 64, 4, 4]             184,384\n",
       "│    │    └─BatchNorm2d: 3-65            [2, 64, 4, 4]             128\n",
       "│    │    └─Upsample: 3-66               [2, 64, 8, 8]             --\n",
       "│    │    └─ReLU: 3-67                   [2, 64, 8, 8]             --\n",
       "├─BlockUT: 1-20                          [2, 64, 8, 8]             --\n",
       "│    └─Sequential: 2-21                  [2, 64, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-68                 [2, 64, 2, 2]             589,888\n",
       "│    │    └─BatchNorm2d: 3-69            [2, 64, 2, 2]             128\n",
       "│    │    └─Upsample: 3-70               [2, 64, 8, 8]             --\n",
       "│    │    └─ReLU: 3-71                   [2, 64, 8, 8]             --\n",
       "├─BlockFUSION: 1-21                      [2, 320, 8, 8]            (recursive)\n",
       "│    └─Sequential: 2-22                  [2, 320, 8, 8]            (recursive)\n",
       "│    │    └─Conv2d: 3-72                 [2, 320, 8, 8]            (recursive)\n",
       "│    │    └─BatchNorm2d: 3-73            [2, 320, 8, 8]            (recursive)\n",
       "│    │    └─ReLU: 3-74                   [2, 320, 8, 8]            --\n",
       "├─BlockPT: 1-22                          [2, 64, 16, 16]           --\n",
       "│    └─Sequential: 2-23                  [2, 64, 16, 16]           --\n",
       "│    │    └─MaxPool2d: 3-75              [2, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-76                 [2, 64, 16, 16]           36,928\n",
       "│    │    └─BatchNorm2d: 3-77            [2, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-78                   [2, 64, 16, 16]           --\n",
       "├─BlockCAT: 1-23                         [2, 64, 16, 16]           --\n",
       "│    └─Sequential: 2-24                  [2, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-79                 [2, 64, 16, 16]           73,792\n",
       "│    │    └─BatchNorm2d: 3-80            [2, 64, 16, 16]           128\n",
       "│    │    └─ReLU: 3-81                   [2, 64, 16, 16]           --\n",
       "├─BlockUT: 1-24                          [2, 64, 16, 16]           --\n",
       "│    └─Sequential: 2-25                  [2, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-82                 [2, 64, 8, 8]             184,384\n",
       "│    │    └─BatchNorm2d: 3-83            [2, 64, 8, 8]             128\n",
       "│    │    └─Upsample: 3-84               [2, 64, 16, 16]           --\n",
       "│    │    └─ReLU: 3-85                   [2, 64, 16, 16]           --\n",
       "├─BlockUT: 1-25                          [2, 64, 16, 16]           --\n",
       "│    └─Sequential: 2-26                  [2, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-86                 [2, 64, 4, 4]             184,384\n",
       "│    │    └─BatchNorm2d: 3-87            [2, 64, 4, 4]             128\n",
       "│    │    └─Upsample: 3-88               [2, 64, 16, 16]           --\n",
       "│    │    └─ReLU: 3-89                   [2, 64, 16, 16]           --\n",
       "├─BlockUT: 1-26                          [2, 64, 16, 16]           --\n",
       "│    └─Sequential: 2-27                  [2, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-90                 [2, 64, 2, 2]             589,888\n",
       "│    │    └─BatchNorm2d: 3-91            [2, 64, 2, 2]             128\n",
       "│    │    └─Upsample: 3-92               [2, 64, 16, 16]           --\n",
       "│    │    └─ReLU: 3-93                   [2, 64, 16, 16]           --\n",
       "├─BlockFUSION: 1-27                      [2, 320, 16, 16]          (recursive)\n",
       "│    └─Sequential: 2-28                  [2, 320, 16, 16]          (recursive)\n",
       "│    │    └─Conv2d: 3-94                 [2, 320, 16, 16]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-95            [2, 320, 16, 16]          (recursive)\n",
       "│    │    └─ReLU: 3-96                   [2, 320, 16, 16]          --\n",
       "├─BlockCAT: 1-28                         [2, 64, 32, 32]           --\n",
       "│    └─Sequential: 2-29                  [2, 64, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-97                 [2, 64, 32, 32]           36,928\n",
       "│    │    └─BatchNorm2d: 3-98            [2, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-99                   [2, 64, 32, 32]           --\n",
       "├─BlockUT: 1-29                          [2, 64, 32, 32]           --\n",
       "│    └─Sequential: 2-30                  [2, 64, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-100                [2, 64, 16, 16]           184,384\n",
       "│    │    └─BatchNorm2d: 3-101           [2, 64, 16, 16]           128\n",
       "│    │    └─Upsample: 3-102              [2, 64, 32, 32]           --\n",
       "│    │    └─ReLU: 3-103                  [2, 64, 32, 32]           --\n",
       "├─BlockUT: 1-30                          [2, 64, 32, 32]           --\n",
       "│    └─Sequential: 2-31                  [2, 64, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-104                [2, 64, 8, 8]             184,384\n",
       "│    │    └─BatchNorm2d: 3-105           [2, 64, 8, 8]             128\n",
       "│    │    └─Upsample: 3-106              [2, 64, 32, 32]           --\n",
       "│    │    └─ReLU: 3-107                  [2, 64, 32, 32]           --\n",
       "├─BlockUT: 1-31                          [2, 64, 32, 32]           --\n",
       "│    └─Sequential: 2-32                  [2, 64, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-108                [2, 64, 4, 4]             184,384\n",
       "│    │    └─BatchNorm2d: 3-109           [2, 64, 4, 4]             128\n",
       "│    │    └─Upsample: 3-110              [2, 64, 32, 32]           --\n",
       "│    │    └─ReLU: 3-111                  [2, 64, 32, 32]           --\n",
       "├─BlockUT: 1-32                          [2, 64, 32, 32]           --\n",
       "│    └─Sequential: 2-33                  [2, 64, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-112                [2, 64, 2, 2]             589,888\n",
       "│    │    └─BatchNorm2d: 3-113           [2, 64, 2, 2]             128\n",
       "│    │    └─Upsample: 3-114              [2, 64, 32, 32]           --\n",
       "│    │    └─ReLU: 3-115                  [2, 64, 32, 32]           --\n",
       "├─BlockFUSION: 1-33                      [2, 320, 32, 32]          (recursive)\n",
       "│    └─Sequential: 2-34                  [2, 320, 32, 32]          (recursive)\n",
       "│    │    └─Conv2d: 3-116                [2, 320, 32, 32]          (recursive)\n",
       "│    │    └─BatchNorm2d: 3-117           [2, 320, 32, 32]          (recursive)\n",
       "│    │    └─ReLU: 3-118                  [2, 320, 32, 32]          --\n",
       "├─Conv2d: 1-34                           [2, 1, 32, 32]            2,881\n",
       "==========================================================================================\n",
       "Total params: 24,202,945\n",
       "Trainable params: 24,202,945\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.40\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 26.66\n",
       "Params size (MB): 96.81\n",
       "Estimated Total Size (MB): 123.48\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(f\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DIM = 2\n",
    "HWD = 32\n",
    "BATCH = 2\n",
    "CHANNEL = 1\n",
    "\n",
    "if DIM == 3: input_size = (BATCH, CHANNEL, HWD, HWD, HWD)\n",
    "elif DIM == 2: input_size = (BATCH, CHANNEL, HWD, HWD)\n",
    "else: raise NotImplementedError\n",
    "\n",
    "model = CustomUNet3Plus(in_channels=CHANNEL, n_classes=1, spatial_dims=DIM, feature_scale=4, is_deconv=True, is_batchnorm=True)\n",
    "summary(model, input_size=input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
